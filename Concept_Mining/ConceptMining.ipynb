{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from ConceptMining import ConceptMiner\n",
    "from settings import settings\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 70\n",
    "images = [i for i in glob(\"../dataset/Images/*.jpg\")]\n",
    "Miner = ConceptMiner(images = images, load_model= True)\n",
    "\n",
    "# encodings, captions = Miner.get_image_caption(get_encodings = True, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('encodings.pkl', 'wb') as f:\n",
    "#     pickle.dump({'encodings':encodings, 'captions': captions}, f)\n",
    "with open('encodings.pkl', 'rb') as f:\n",
    "\tdata = pickle.load(f)\n",
    "\tencodings = data['encodings']\n",
    "\tcaptions = data['captions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_model, generated_concepts = Miner.concept_modeling(encodings = encodings, \n",
    "                                                           captions = captions, \n",
    "                                                           batch_size = batch_size)\n",
    "\n",
    "with open(\"generated_concepts.pkl\", \"wb\") as f:\n",
    "    pickle.dump(generated_concepts, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluser topics by semantic similarity \n",
    "- Cluser concepts\n",
    "- Sample concepts taking as mean the centroid +- a random noice to simulate user externalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import KMeans\n",
    "from umap import UMAP\n",
    "import os, pickle\n",
    "import numpy as np\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "with open(\"generated_concepts.pkl\", \"rb\") as f:\n",
    "    generated_concepts = list(set(pickle.load(f)) - {\"\"})\n",
    "    \n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "model = AutoModel.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "def get_embedding(sentences, model, tokenizer, batch_size = 16):\n",
    "    with torch.no_grad():\n",
    "\n",
    "        output = None\n",
    "        for i in range(0, len(sentences), batch_size):\n",
    "            encoded_input = tokenizer(sentences[i: i + batch_size], padding=True, return_tensors='pt')\n",
    "\n",
    "            model_output = model(**encoded_input)\n",
    "            sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "\n",
    "            sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n",
    "            output = sentence_embeddings if output is None else torch.cat([output, sentence_embeddings])\n",
    "\n",
    "    return output\n",
    "\n",
    "concepts_embeddings = get_embedding(generated_concepts, model, tokenizer, batch_size = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "similarity_matrix = cosine_similarity(concepts_embeddings)\n",
    "\n",
    "# Apply Spectral Clustering\n",
    "num_clusters = 20\n",
    "spectral = SpectralClustering(n_clusters=num_clusters, affinity='precomputed', random_state=42)\n",
    "labels = spectral.fit_predict(similarity_matrix)\n",
    "\n",
    "# Group words by topic\n",
    "topic_groups = {}\n",
    "for word, cluster in zip(generated_concepts, labels):\n",
    "    topic_groups.setdefault(cluster, []).append(word)\n",
    "    \n",
    "with open(\"generated_concepts.pkl\", \"wb\") as f:\n",
    "\tpickle.dump({'concepts':generated_concepts,\n",
    "              'topic_groups': topic_groups}, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess the data for simulation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from glob import glob\n",
    "\n",
    "import random\n",
    "\n",
    "with open(\"generated_concepts.pkl\", \"rb\") as f:\n",
    "\tdata = pickle.load(f)\n",
    "\tgenerated_concepts = data['concepts']\n",
    "\ttopic_groups = data['topic_groups']\n",
    "\n",
    "with open('encodings.pkl', 'rb') as f:\n",
    "\tdata = pickle.load(f)\n",
    "\tencodings = data['encodings']\n",
    "\tcaptions = data['captions']\n",
    "\n",
    "images = [i for i in glob(\"../dataset/Images/*.jpg\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Encode all text and images to speed up training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "\n",
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(\"cuda\")\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "batch_size = 70\n",
    "# encode all images using output of a single text\n",
    "image_encodings = []\n",
    "\n",
    "for batch in tqdm(range(0, len(images), batch_size)):\n",
    "\timage = [Image.open(i) for i in images[batch: batch + batch_size]]\n",
    "\tinputs = processor(text=[\"a photo of a cat\"] * len(image), images=image, return_tensors=\"pt\", padding=True).to(\"cuda\")\n",
    "\toutputs = model(**inputs, return_dict = True)\n",
    "\timage_encodings += [outputs.image_embeds.cpu().detach()]\n",
    "\n",
    "image_encodings = torch.cat(image_encodings)\n",
    "\n",
    "# encode all concepts using output of a single image\n",
    "concept_encodings = []\n",
    "for batch in tqdm(range(0, len(generated_concepts), batch_size)):\n",
    "\tconcepts = generated_concepts[batch: batch + batch_size]\n",
    "\tinputs = processor(text=concepts, images=[Image.open(images[0])], return_tensors=\"pt\", padding=True).to(\"cuda\")\n",
    "\toutputs = model(**inputs, return_dict = True)\n",
    "\tconcept_encodings += [outputs.text_embeds.cpu().detach()]\n",
    "\n",
    "concept_encodings = torch.cat(concept_encodings)\n",
    "with open(\"clip_encodings.pkl\", \"wb\") as f:\n",
    "\tpickle.dump({'image_encodings': image_encodings,\n",
    "\t\t\t  'concept_encodings': concept_encodings}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_instance = {i:[] for i in generated_concepts}\n",
    "\n",
    "for i, path in enumerate(images):\n",
    "\tfor c in captions[i].split():\n",
    "\t\tif c in generated_concepts:\n",
    "\t\t\tconcept_instance[c] += [path]\n",
    "\n",
    "remove_topics = []\n",
    "for i in topic_groups:\n",
    "\tremove = [j for j in topic_groups[i] if len(concept_instance[j]) < 10]\n",
    "\tfor j in remove:\n",
    "\t\ttopic_groups[i].remove(j)\n",
    "\tprint(f\"Topic {i}:\", len(topic_groups[i]))\n",
    "\tif len(topic_groups[i]) < 8:\n",
    "\t\tremove_topics.append(i)\n",
    "\n",
    "for i in remove_topics:\n",
    "\tdel topic_groups[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\t\n",
    "plt.bar(range(len(generated_concepts)), sorted([len(i) for i in concept_instance.values()]), log = True)\n",
    "plt.title(\"Concepts Frequency\")\n",
    "plt.xlabel(\"Concepts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(range(len(topic_groups)), [len(topic_groups[i]) for i in topic_groups], color = 'r')\n",
    "plt.title(\"Topics Size\")\n",
    "plt.xlabel(\"Topics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# from Actor_Critic import AdaptationEngine\n",
    "from ContextualBandit import AdaptationEngine\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "import random; random.seed(42)\n",
    "\n",
    "\n",
    "def encode_actions(action, n_actions):\n",
    "\n",
    "\tif not isinstance(action, torch.Tensor):\n",
    "\t\taction = torch.tensor(action)\n",
    "\treturn torch.nn.functional.one_hot(action, num_classes=n_actions).float()\n",
    "\n",
    "def preprocess_state(state):\n",
    "\treturn torch.tensor(state).float().reshape(1, -1)\n",
    "\n",
    "def get_entropy(preferences):\n",
    "\treturn -torch.sum(preferences * torch.log(preferences), dim = -1)\n",
    "\n",
    "episodes = 0\n",
    "episode_length = 1000\n",
    "dataset_coverage_step = .75\n",
    "gamma = 0.99\n",
    "buffer = []\n",
    "actions_embedd_dim = 2\n",
    "buffer_size = 245\n",
    "\n",
    "lr_actor = 0.01\n",
    "lr_critic = 0.0001\n",
    "\n",
    "temperature = .2\n",
    "final_temperature = 0.1\n",
    "decay_rate = 0.999  # Decay per episode\n",
    "\n",
    "\n",
    "# env = gym.make('MountainCar-v0')\n",
    "env = gym.make('CartPole-v1')\n",
    "\n",
    "# Pi = Actor(state_dim = env.observation_space.shape[0], action_dim = actions_embedd_dim, lr_optimizer = lr_actor)\n",
    "# V = Critic(state_dim = env.observation_space.shape[0], lr_optimizer = lr_critic)\n",
    "Agent = AdaptationEngine(state_dim = env.observation_space.shape[0],\n",
    "\t\t\t\t\t\t action_space_len=env.action_space.n,\n",
    "\t\t\t\t\t\t \taction_dim=env.action_space.n,\n",
    "\t\t\t\t\t\t\tlr_actor = lr_actor,\n",
    "\t\t\t\t\t\t\tlr_critic = lr_critic,\n",
    "\t\t\t\t\t\t\tgamma = gamma,\n",
    "\t\t\t\t\t\t\tbuffer_size = buffer_size,\n",
    "\t\t\t\t\t\t\tsample_temperature = temperature,\n",
    "\t\t\t\t\t\t\tfinal_temperature = final_temperature,\n",
    "\t\t\t\t\t\t\ttemperatura_decay = decay_rate)\n",
    "\n",
    "actions_encode = encode_actions([i  for i in range(env.action_space.n)], env.action_space.n).to(Agent.device)\n",
    "\n",
    "episode_history = {'rewards': [],\n",
    "\t\t    'loss_critic': [], \n",
    "\t\t\t'loss_actor': []}\n",
    "\n",
    "history = {'rewards': [],\n",
    "\t\t    'loss_critic': [], \n",
    "\t\t\t'loss_actor': []}\n",
    "\n",
    "\n",
    "for episode in range(episodes):\n",
    "\n",
    "\tprev_state, _ = env.reset()\n",
    "\tprev_state = preprocess_state(prev_state)\n",
    "\n",
    "\tepisode_history = {'rewards': [],\n",
    "\t\t'loss_critic': [], \n",
    "\t\t'loss_actor': [],\n",
    "\t\t'entropy': []}\n",
    "\t\t\t\n",
    "\titera = tqdm(range(episode_length))\n",
    "\titera.set_description(f\"Episode {episode}\")\n",
    "\n",
    "\tfor step in itera:\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tAgent.eval()\n",
    "\t\t\tpreferences = Agent.policy(prev_state, actions_encode)\t\n",
    "\t\t\t# print(preferences)\n",
    "\t\t\t\n",
    "\t\t\tif random.random() < Agent.temperature:\n",
    "\t\t\t\taction = torch.randint(0, env.action_space.n, (1,)).item()\n",
    "\t\t\telse:\n",
    "\t\t\t\taction = torch.argmax(preferences).item()\n",
    "\t\t\t\n",
    "\t\t\tstate, reward, done, truncated, _ = env.step(action)\n",
    "\t\t\tstate = preprocess_state(state)\n",
    "\t\tAgent.train()\n",
    "\n",
    "\t\tAgent.push_buffer(state=prev_state,\n",
    "\t\t\t\t\t action=torch.tensor(action), \n",
    "\t\t\t\t\t reward=reward, \n",
    "\t\t\t\t\t next_state=state, \n",
    "\t\t\t\t\t done=done)\n",
    "\t\t\n",
    "\t\tepisode_history['rewards'].append(reward)\n",
    "\t\t# episode_history['entropy'].append(get_entropy(preferences).mean().item())\n",
    "\n",
    "\t\tif Agent.buffer_size <= len(Agent.buffer):\n",
    "\t\t\tactor_loss = Agent.optimization_step(actions_encode)\n",
    "\t\t\t# actor_loss, critic_loss = Agent.optimization_step(actions_encode)\n",
    "\t\t\t# episode_history['loss_critic'].append(critic_loss)\n",
    "\t\t\tepisode_history['loss_actor'].append(actor_loss)\n",
    "\n",
    "\t\tprev_state = state\n",
    "\n",
    "\t\titera.set_postfix({'Temperature': f'{temperature:.4f}',\n",
    "\t\t\t\t\t\t'Reward': sum(episode_history['rewards']),\n",
    "\t\t\t\t\t\t# 'entropy': sum(episode_history['entropy']),\n",
    "\t\t\t\t\t\t# 'Loss Critic': sum(episode_history['loss_critic']),\n",
    "\t\t\t\t\t\t'Loss Actor': sum(episode_history['loss_actor'])} )\n",
    "\t\tif done or truncated:\n",
    "\t\t\thistory['rewards'].append(sum(episode_history['rewards']))\n",
    "\t\t\t# history['loss_critic'].append(sum(episode_history['loss_critic']))\n",
    "\t\t\thistory['loss_actor'].append(sum(episode_history['loss_actor']))\n",
    "\t\t\tbreak\n",
    "\n",
    "\ttemperature = max(final_temperature, temperature * decay_rate)\n",
    "\tif Agent.max_reward is None or Agent.max_reward < sum(episode_history['rewards']):\n",
    "\t\tAgent.max_reward = sum(episode_history['rewards'])\n",
    "\t\tAgent.Actor.save(f\"bandit.pt\")\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Agent.eval()\n",
    "print(Agent.policy(prev_state, actions_encode))\n",
    "prev_state\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history['rewards'])\n",
    "plt.title(\"Rewards\")\n",
    "plt.xlabel(\"Iterations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# from Actor_Critic import AdaptationEngine\n",
    "from ContextualBandit import AdaptationEngine\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython import display\n",
    "\n",
    "def show_state(env, step=0):\n",
    "    plt.figure(3)\n",
    "    plt.clf()\n",
    "    plt.imshow(env.render())\n",
    "    plt.title(f\"Step: {step}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())\n",
    "\n",
    "\n",
    "env = gym.make('CartPole-v1', render_mode='rgb_array')\n",
    "Agent = AdaptationEngine(state_dim = env.observation_space.shape[0],\n",
    "\t\t\t\t\t\t action_space_len=env.action_space.n,\n",
    "\t\t\t\t\t\t\taction_dim=env.action_space.n)\n",
    "\n",
    "# Agent = AdaptationEngine(state_dim = env.observation_space.shape[0],\n",
    "\t\t\t\t\t\t \n",
    "# \t\t\t\t\t\t \taction_dim=env.action_space.n,\n",
    "# \t\t\t\t\t\t\tlr_actor = lr_actor,\n",
    "# \t\t\t\t\t\t\tlr_critic = lr_critic,\n",
    "# \t\t\t\t\t\t\tgamma = gamma,\n",
    "# \t\t\t\t\t\t\tbuffer_size = buffer_size,\n",
    "# \t\t\t\t\t\t\tsample_temperature = temperature,\n",
    "# \t\t\t\t\t\t\tfinal_temperature = final_temperature,\n",
    "# \t\t\t\t\t\t\ttemperatura_decay = decay_rate)\n",
    "                            \n",
    "Agent.Actor.load('bandit.pt')\n",
    "Agent.eval()\n",
    "# env = gym.make('MountainCar-v0', render_mode='rgb_array')\n",
    "\n",
    "prev_state, info = env.reset()\n",
    "prev_state = preprocess_state(prev_state)\n",
    "print(prev_state)\n",
    "for step in range(int(100)):\n",
    "\tpreferences =  Agent.policy(prev_state, actions_encode)\n",
    "\n",
    "\taction = preferences.argmax()\n",
    "\n",
    "\tobservation, reward, terminated, _, _ = env.step(action.item())\n",
    "\tprint(action)\n",
    "\n",
    "\tprev_state = preprocess_state(observation)\n",
    "\tprev_action = action\n",
    "\n",
    "\tshow_state(env, step=step)\n",
    "\n",
    "\tif terminated:\n",
    "\t\tprint(observation)\n",
    "\t\tbreak\n",
    "\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optuna for settings (hyperparameters - actor critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random; random.seed(0)\n",
    "import numpy as np; np.random.seed(0)\n",
    "\n",
    "from utils import train_agent\n",
    "\n",
    "settings = {'episode_length': 1000,\n",
    "            'episodes': 3000,\n",
    "            'gamma': 0.99,\n",
    "            'decay_rate': 0.95,\n",
    "            'buffer_size': 256,\n",
    "            'lr_critic': 5e-4, #3e-4 #0.002159000868210698,\n",
    "            'lr_actor': 3e-4, #1e-4#0.0007674507120792033,\n",
    "            'temperature': 5,\n",
    "\t\t\t'final_temperature': 1}\n",
    "    \n",
    "\n",
    "average_reward, deviation_reward, history = train_agent(settings, use_mlflow = False, save_suffix = \"_best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simualte Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "from glob import glob\n",
    "\n",
    "from Concept_Mining.SimulationEnvironment import explore_environment\n",
    "from Actor_Critic import AdaptationEngine\n",
    "from settings import  pretraining_settings as settings\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def get_entropy(preferences):\n",
    "\treturn -torch.sum(preferences * torch.log(preferences), dim = -1)\n",
    "\n",
    "with open(\"clip_encodings.pkl\", \"rb\") as f:\n",
    "\tdata = pickle.load(f)\n",
    "\timage_encodings = data['image_encodings']\n",
    "\tactions_encode = data['concept_encodings']\n",
    "\n",
    "with open(\"generated_concepts.pkl\", \"rb\") as f:\n",
    "\tdata = pickle.load(f)\n",
    "\tgenerated_concepts = data['concepts']\n",
    "\ttopic_groups = data['topic_groups']\n",
    "\n",
    "with open('encodings.pkl', 'rb') as f:\n",
    "\tcaptions = pickle.load(f)['captions']\n",
    "\n",
    "images = [i for i in glob(\"../dataset/Images/*.jpg\")]\n",
    "\n",
    "Agent = AdaptationEngine(state_dim = image_encodings.shape[1] + actions_encode.shape[1],\n",
    "\t\t\t\t\t\t \taction_dim=actions_encode.shape[1],\n",
    "\t\t\t\t\t\t\taction_space_len=actions_encode.shape[0],\n",
    "\t\t\t\t\t\t\tlr_actor = settings.lr_actor,\n",
    "\t\t\t\t\t\t\tlr_critic = settings.lr_critic,\n",
    "\t\t\t\t\t\t\tgamma = settings.gamma,\n",
    "\t\t\t\t\t\t\tbuffer_size = settings.buffer_size,\n",
    "\t\t\t\t\t\t\tsample_temperature = settings.temperature,\n",
    "\t\t\t\t\t\t\tfinal_temperature = settings.final_temperature,\n",
    "\t\t\t\t\t\t\ttemperature_decay = settings.decay_rate)\n",
    "\n",
    "def get_trajectory( env_snapshot, state, trajectory_len: int = 10 ):\n",
    "\t\n",
    "\tcurrent_path = []\n",
    "\tprocessed_state = env_snapshot.preprocess_state(state)\n",
    "\n",
    "\tfor _ in range(trajectory_len):\n",
    "\t\t\n",
    "\t\tpreferences = Agent.policy(processed_state, actions_encode)\n",
    "\t\taction = preferences.argmax() #torch.multinomial(preferences, 1).squeeze(-1)\n",
    "\t\t\n",
    "\t\tcurrent_path.append(action.item())\n",
    "\t\tprocessed_state = env_snapshot.preprocess_state(state, current_path=current_path)\n",
    "\t\n",
    "\treturn current_path\n",
    "\n",
    "env = explore_environment(topic_groups=topic_groups, \n",
    "\t\t\t\t\t\t  concepts=generated_concepts,\n",
    "\t\t\t\t\t\t  concepts_encode=actions_encode,\n",
    "\t\t\t\t\t\t  images=images,\n",
    "\t\t\t\t\t\t  images_caption=captions,\n",
    "\t\t\t\t\t\t  images_encode=image_encodings, \n",
    "\t\t\t\t\t\t  threshold=10)\n",
    "\n",
    "\n",
    "Agent.Actor.load('actor_9.pt')\n",
    "Agent.eval()\n",
    "# Agent.Critic.load('critic_best.pt')\n",
    "prediction = []\n",
    "remaining = []\n",
    "\n",
    "taken_actions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "\tfor episode in range(1):\n",
    "\n",
    "\t\tepisode_index, (prev_state, feedback, _) = env.reset()\n",
    "\t\tprev_state = env.preprocess_state(prev_state)\n",
    "\n",
    "\t\tenv.externalized.add(feedback)\n",
    "\t\t\t\t\n",
    "\t\titera = tqdm(range(len(env.topic)))\n",
    "\t\titera.set_description(f\"Episode {episode}\")\n",
    "\n",
    "\t\tfor step in itera:\n",
    "\n",
    "\t\t\t# actions_trajectory = get_trajectory(env, prev_state, trajectory_len = 10)\n",
    "\n",
    "\t\t\t# prediction.append(actions_trajectory.copy())\n",
    "\t\t\t# remaining.append(env.topic[env.step_index:].copy())\n",
    "\t\t\tpreferences = Agent.policy(prev_state, actions_encode)\n",
    "\t\t\taction = torch.multinomial(preferences, 1).squeeze(-1)\n",
    "\n",
    "\t\t\tstate, feedback, _, done = env.step( action.item() )\n",
    "\t\t\ttaken_actions.append(action.item())\n",
    "\t\t\tprint(action.item(), generated_concepts[action.item()])\n",
    "\t\t\tstate = env.preprocess_state(state)\n",
    "\t\t\t# state, feedback, _, done = env.step( actions_trajectory[0] )\n",
    "\t\t\tenv.externalized.add(feedback)\n",
    "\t\t\t# actions_trajectory = state\n",
    "\t\t\tprev_state = state\n",
    "\n",
    "\t\t\tif done:\n",
    "\t\t\t\tbreak\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "np.random.seed(42)\n",
    "embeddings_1 = actions_encode[env.topic]\n",
    "\n",
    "embeddings_2 = actions_encode[taken_actions] \n",
    "Set1 = [\"Externalized\"]*len(embeddings_1) \n",
    "Set2 = [\"Proposed\"]*len(embeddings_2)  # Labels for second set\n",
    "\n",
    "labels_1 = [generated_concepts[i] for i in env.topic] \n",
    "labels_2 = [generated_concepts[i] for i in taken_actions] # Labels for second set\n",
    "\n",
    "# Concatenate embeddings\n",
    "embeddings = np.vstack([embeddings_1, embeddings_2])\n",
    "labels = labels_1 + labels_2  # Merge labels\n",
    "Sets = Set1 + Set2\n",
    "\n",
    "# Dimensionality Reduction (Use TSNE or UMAP)\n",
    "reducer = TSNE(n_components=2, perplexity=5, random_state=42)\n",
    "reduced_embeddings = reducer.fit_transform(embeddings)\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(reduced_embeddings, columns=[\"x\", \"y\"])\n",
    "df[\"Set\"] = Sets  # Assign label to distinguish sets\n",
    "df[\"Label\"] = labels  # Assign label for hover\n",
    "\n",
    "\n",
    "# Custom color mapping (Red for Set 1, Blue for Set 2)\n",
    "color_map = {\"Set 1\": \"red\", \"Set 2\": \"blue\"}\n",
    "\n",
    "# Interactive Plot\n",
    "fig = px.scatter(df, x=\"x\", y=\"y\", color=\"Set\", hover_data=[\"Label\"], title=\"Comparison of Two Embedding Sets\",\n",
    "                 color_discrete_map=color_map, size_max=30)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from glob import glob\n",
    "from SimulationEnvironment import explore_environment\n",
    "\n",
    "\n",
    "with open(\"clip_encodings.pkl\", \"rb\") as f:\n",
    "\tdata = pickle.load(f)\n",
    "\timage_encodings = data['image_encodings']\n",
    "\tactions_encode = data['concept_encodings']\n",
    "\n",
    "with open(\"generated_concepts.pkl\", \"rb\") as f:\n",
    "\tdata = pickle.load(f)\n",
    "\tgenerated_concepts = data['concepts']\n",
    "\ttopic_groups = data['topic_groups']\n",
    "\n",
    "with open('encodings.pkl', 'rb') as f:\n",
    "\tcaptions = pickle.load(f)['captions']\n",
    "\n",
    "images = [i for i in glob(\"../dataset/Images/*.jpg\")]\n",
    "\n",
    "env = explore_environment(topic_groups=topic_groups, \n",
    "\t\t\t\t\t\tconcepts=generated_concepts,\n",
    "\t\t\t\t\t\tconcepts_encode=actions_encode,\n",
    "\t\t\t\t\t\timages=images,\n",
    "\t\t\t\t\t\timages_caption=captions,\n",
    "\t\t\t\t\t\timages_encode=image_encodings, \n",
    "\t\t\t\t\t\tthreshold=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = env.reset(1)\n",
    "# episode_index, (prev_state, feedback, _) = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 6\n",
      "288 106 2.0 False\n",
      "288 36 -5.0 False\n",
      "288 39 -5.0 False\n",
      "288 47 -5.0 False\n",
      "288 58 -5.0 False\n",
      "288 10 -5.0 False\n",
      "288 120 -5.0 False\n",
      "288 121 -5.0 False\n",
      "288 163 -5.0 False\n",
      "288 167 -5.0 False\n",
      "288 200 -5.0 False\n",
      "288 235 -5.0 False\n",
      "288 246 -5.0 False\n",
      "288 295 -5.0 False\n",
      "288 296 -5.0 False\n",
      "288 331 -5.0 False\n",
      "288 336 -5.0 False\n",
      "288 340 -5.0 False\n",
      "288 434 -5.0 False\n",
      "288 466 -5.0 False\n",
      "288 471 -5.0 False\n",
      "288 473 -5.0 False\n",
      "288 475 -5.0 False\n",
      "288 481 -5.0 False\n",
      "288 523 -5.0 False\n",
      "288 534 -5.0 False\n",
      "0 568 -5.0 True\n"
     ]
    }
   ],
   "source": [
    "x[1][1]\n",
    "\n",
    "itera = range(len(env.topic) - 1)\n",
    "\n",
    "taken_actions = []\n",
    "\n",
    "for _ in itera:\n",
    "    z = env.step(106)\n",
    "    print(len(z[0]), z[1], z[2], z[3])\n",
    "    env.externalized.add(z[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "288 10 0.91170734 False\n",
    "288 36 0.91170734 False\n",
    "288 39 0.91170734 False\n",
    "288 47 0.91170734 False\n",
    "288 58 0.91170734 False\n",
    "288 106 0.91170734 False\n",
    "288 120 0.91170734 False\n",
    "288 121 0.91170734 False\n",
    "288 163 0.91170734 False\n",
    "288 167 0.91170734 False\n",
    "288 200 0.91170734 False\n",
    "288 235 0.9040707 False\n",
    "288 246 0.9040707 False\n",
    "288 295 0.9040707 False\n",
    "288 296 0.9040707 False\n",
    "288 331 0.9040707 False\n",
    "288 336 0.9040707 False\n",
    "288 340 0.9040707 False\n",
    "288 434 0.9040707 False\n",
    "288 466 0.9040707 False\n",
    "288 471 0.9040707 False\n",
    "288 473 0.9040707 False\n",
    "288 475 0.90072924 False\n",
    "288 481 0.90072924 False\n",
    "288 523 0.90072924 False\n",
    "288 534 0.89102805 False\n",
    "0 568 0.89102805 True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
